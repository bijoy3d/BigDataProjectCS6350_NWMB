{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ef77dc2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:32:41.645732Z",
     "start_time": "2021-11-25T18:32:41.636504Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f3a7b285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:32:41.661716Z",
     "start_time": "2021-11-25T18:32:41.647641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]]\n",
      "--\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "dataset=StringIO(\"\"\"Date,Open,High,Low,Close,Volume,Trade_count,Vwap\n",
    "2015-12-01 09:00:00+00:00,118.88,118.94,118.88,118.94,1145,5,118.902052\n",
    "2015-12-01 09:15:00+00:00,118.77,118.77,118.77,118.77,200,1,118.77\n",
    "2015-12-01 09:30:00+00:00,118.69,118.69,118.6,118.6,900,4,118.61\n",
    "2015-12-01 09:45:00+00:00,118.64,118.65,118.64,118.65,3580,5,118.648883\n",
    "2015-12-01 10:00:00+00:00,118.65,118.65,118.55,118.55,1820,4,118.611538\n",
    "2015-12-01 10:15:00+00:00,118.55,118.6,118.55,118.6,880,5,118.5625\n",
    "2015-12-01 10:30:00+00:00,118.55,118.55,118.5,118.5,1878,5,118.513312\n",
    "2015-12-01 10:45:00+00:00,118.59,118.72,118.59,118.72,2499,10,118.628431\n",
    "2015-12-01 11:00:00+00:00,118.71,118.9,118.71,118.9,2842,11,118.86064\n",
    "2015-12-01 11:15:00+00:00,118.87,118.87,118.87,118.87,300,2,118.87\n",
    "2015-12-01 11:30:00+00:00,118.78,118.8,118.76,118.8,3914,22,118.785876\n",
    "2015-12-01 11:45:00+00:00,118.8,118.99,118.77,118.9,7900,37,118.893542\n",
    "2015-12-01 12:00:00+00:00,118.88,118.98,118.84,118.84,6540,34,118.922648\n",
    "2015-12-01 12:15:00+00:00,118.82,118.84,118.77,118.77,5603,28,118.804962\n",
    "2015-12-01 12:30:00+00:00,118.77,118.89,118.76,118.88,7612,31,118.824002\n",
    "\"\"\")\n",
    "df = pd.read_table(dataset, sep=\",\")\n",
    "\n",
    "#ip = np.array([ [1,2,3],[6,8,9],[3,4,5],[4,7,8],[4,2,5],[5,7,4] ])\n",
    "#op = np.array([[2,8,4,7,2,4]])\n",
    "#op = op.reshape(6,1)\n",
    "ip = np.array([ [1],  [2],  [0],  [2],  [0],  [1],  [2],  [1] ])\n",
    "op = np.array([ [300],[100],[200],[100],[200],[300],[100],[300] ])\n",
    "num_steps = 3\n",
    "num_features = 1\n",
    "#ip_shaped = np.reshape(ip, newshape=(-1, num_steps, num_features))\n",
    "\n",
    "#X = np.array([ [1,2,3, 4, 5, 6] ])\n",
    "#Y = np.array([[2,3,4,5,6,7]])\n",
    "print(ip)\n",
    "print(\"--\")\n",
    "#ip= np.tile(ip,(50,1))\n",
    "#op = np.tile(op,(50,1))\n",
    "print(len(op))\n",
    "#ip = np.array([ [1],[1],[1],[1],[1],[2],[1],[2]])\n",
    "#op = np.array([ [1,    0,    1,    0,    1,    1,    0,    1 ]]).T\n",
    "\n",
    "ip = np.array([ [1,1,2],[1,2,1],[1,0,2],[1,2,1],[1,0,2],[1,1,2],[1,2,1],[1,1,2]])\n",
    "op = np.array([ [10,    20,    10,    20,    10,    10,    20,    10 ]]).T\n",
    "#ip = np.array([ [1,1,1,1,1],[0,2,2,2,2],[1,3,3,3,3],[1,4,4,4,4],[0,5,5,5,5],[0,6,6,6,6],[1,7,7,7,7],[0,8,8,8,8]])\n",
    "#op = np.array([ [1,          0,          1,          1,          0,          0,          1,          0 ]]).T\n",
    "_, numFeats = ip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1581704c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:32:41.674539Z",
     "start_time": "2021-11-25T18:32:41.663842Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm_data_transform(x_data, y_data, timeSteps=2):\n",
    "    \"\"\" Changes data to the format for LSTM training \n",
    "for sliding window approach \"\"\"\n",
    "    # Prepare the list for the transformed data\n",
    "    X, y = list(), list()\n",
    "    # Loop of the entire data set\n",
    "    #print(x_data.shape[0])\n",
    "    for i in range(x_data.shape[0]):\n",
    "        # compute a new (sliding window) index\n",
    "        end_ix = i + timeSteps\n",
    "\n",
    "        # if index is larger than the size of the dataset, we stop\n",
    "        #print(end_ix)\n",
    "        if end_ix >= x_data.shape[0]:\n",
    "            break\n",
    "        # Get a sequence of data for x\n",
    "        seq_X = x_data[i:end_ix]\n",
    "        #print(x_data[i:end_ix])\n",
    "        # Get only the last element of the sequency for y\n",
    "        #print(y_data[end_ix])\n",
    "        seq_y = y_data[i:end_ix]\n",
    "        # Append the list with sequencies\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        display(X)\n",
    "        print(\"--\")\n",
    "    # Make final arrays\n",
    "    x_array = np.array(X)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array\n",
    "\n",
    "def lstm_data_time(x_data, y_data, timeSteps=2):\n",
    "    \"\"\" Changes data to the format for LSTM training \n",
    "for sliding window approach \"\"\"\n",
    "    # Prepare the list for the transformed data\n",
    "    X, y = list(), list()\n",
    "    # Loop of the entire data set\n",
    "    #print(x_data.shape[0])\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "\n",
    "    for i in range(x_data.shape[0]):\n",
    "        my2, mx2 = list(), list()\n",
    "        # compute a new (sliding window) index\n",
    "        end_ix = i + timeSteps\n",
    "\n",
    "        # if index is larger than the size of the dataset, we stop\n",
    "        #print(end_ix)\n",
    "        if end_ix >= x_data.shape[0]:\n",
    "            break\n",
    "\n",
    "        for j in range(i, i+timeSteps):\n",
    "            my1, mx1 = list(), list()\n",
    "            # Get a sequence of data for x\n",
    "            seq_X = x_data[j]\n",
    "            # Get only the last element of the sequency for y\n",
    "            seq_y = y_data[j]\n",
    "            # Append the list with sequencies\n",
    "            for k in range(len(seq_X)):\n",
    "                my, mx = list(), list()\n",
    "                mx.append(seq_X[k])\n",
    "                mx1.append(mx)\n",
    "                \n",
    "            mx2.append(mx1)\n",
    "            my2.append(seq_y)\n",
    "            \n",
    "        X.append(mx2)\n",
    "        y.append(my2)\n",
    "\n",
    "        #X.append(np.array(mx1))\n",
    "        #y.append(np.array(my))\n",
    "    # Make final arrays\n",
    "    x_array = np.array(X)\n",
    "    y_array = np.array(y)\n",
    "\n",
    "    return x_array, y_array\n",
    "#3 3 1 want\n",
    "#3 3 3 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8de04139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:32:41.703477Z",
     "start_time": "2021-11-25T18:32:41.676317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 3)\n",
      "(93, 3, 3, 1)\n",
      "(3, 3, 1)\n",
      "(93, 3, 1)\n",
      "====\n",
      "[[25]\n",
      " [30]\n",
      " [25]]\n"
     ]
    }
   ],
   "source": [
    "timeSteps = 3\n",
    "ip = np.array([ [1,10,20],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20]            \n",
    "              ])\n",
    "# op = np.array([ [1,         1,         0,         1,         0,         1,         0,         0, \n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0\n",
    "#                 ]]).T\n",
    "op = np.array([ [25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45\n",
    "                ]]).T\n",
    "\n",
    "\n",
    "numFeats = 3\n",
    "# ip = np.array([ [1,1,2],[1,2,1],[1,0,2],[1,2,1],[1,0,2],[1,1,2],[1,2,1],[1,1,2]])\n",
    "# op = np.array([ [0,    0,    0,    0,    0,    0,    0,    0 ]]).T\n",
    "\n",
    "# ip = np.array([ [[1,2],[1,2],[1,2],[2,3]],[[1,2],[1,2],[2,3],[1,2]],\n",
    "#                 [[1,2],[1,2],[0,1],[2,3]],[[1,2],[1,2],[2,3],[1,2]],\n",
    "#                 [[1,2],[1,2],[0,1],[2,3]],[[1,2],[1,2],[1,2],[2,3]],\n",
    "#                 [[1,2],[1,2],[2,3],[1,2]],[[1,2],[1,2],[1,2],[2,3]]])\n",
    "print(ip.shape)\n",
    "ipt,opt=lstm_data_time(ip,op, timeSteps)\n",
    "print(ipt.shape)\n",
    "print(ipt[0].shape)\n",
    "print(opt.shape)\n",
    "\n",
    "print(\"====\")\n",
    "print(opt[0])\n",
    "# batchSize = len(ipt)\n",
    "# [[[1.]\n",
    "#   [0.]\n",
    "#   [0.]]\n",
    "\n",
    "#  [[1.]\n",
    "#   [0.]\n",
    "#   [0.]]\n",
    "\n",
    "#  [[1.]\n",
    "#   [0.]\n",
    "#   [0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "44a26e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:32:41.714640Z",
     "start_time": "2021-11-25T18:32:41.705129Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the element-wise sigmoid activation function for an array x.\n",
    "\n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    f = 1 / (1 + np.exp(-x_safe))\n",
    "    \n",
    "    if derivative: # Return the derivative of the function evaluated at x\n",
    "        return f * (1 - f)\n",
    "    else: # Return the forward pass of the function at x\n",
    "        return f\n",
    "    \n",
    "\n",
    "def update_lstmData(params, dip, dop, db, lr):\n",
    "    wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = params\n",
    "\n",
    "    t = wa.T - (dip*lr)\n",
    "    wa.T[0] = t[0].T\n",
    "    t = wi.T - (dip*lr)\n",
    "    wi.T[0] = t[1].T\n",
    "    t = wf.T - (dip*lr)\n",
    "    wf.T[0] = t[2].T\n",
    "    t = wo.T - (dip*lr)\n",
    "    wo.T[0] = t[3].T\n",
    "    ua = ua.T - (dop*lr)[0]\n",
    "    ui = ui.T - (dop*lr)[1]\n",
    "    uf = uf.T - (dop*lr)[2]\n",
    "    uo = uo.T - (dop*lr)[3]\n",
    "    ba = ba.T - (db*lr)[0]\n",
    "    bi = bi.T - (db*lr)[1]\n",
    "    bf = bf.T - (db*lr)[2]\n",
    "    bo = bo.T - (db*lr)[3]\n",
    "    return wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "7870a92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T20:19:58.553884Z",
     "start_time": "2021-11-25T20:19:58.443710Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM():\n",
    "    def __init__(self, train_data, targets, batch_size=2, debug=1, test=1):\n",
    "        #4 gates\n",
    "        # input_activation = tanh(wa [inner] input + ua [inner] prev_output + ba)\n",
    "        # input_gate  = sigmoid(wi [inner] input + ui [inner] prev_output + bi)\n",
    "        # forget_gate = sigmoid(wf [inner] input + uf [inner] prev_output + bf)\n",
    "        # output_gate = sigmoid(wo [inner] input + uo [inner] prev_output + bo)\n",
    "\n",
    "        # 2 states\n",
    "        # internal_state = (input_activation [Element wise] input_gate) + (forget_gate [Element wise] prev_internal_state)\n",
    "        # output = tanh(internal_state) [Element wise] output_gate\n",
    "\n",
    "        # To enable test mode. Batch size would be set as 2\n",
    "        self.test = test\n",
    "        \n",
    "        # The number of records that would go inside the LSTM at one time. A sequence of records.\n",
    "        self.batch_size = batch_size\n",
    "        numFeats = 2 ###### CHANGE IT TO GET DYNAMICALLY FROM INPUT\n",
    "        # Enable debug logs\n",
    "        self.debug = debug\n",
    "        \n",
    "        # Training Data\n",
    "        self.train_data = train_data\n",
    "        # Target of training data\n",
    "        self.targets = targets\n",
    "        \n",
    "        \n",
    "        # input_activation\n",
    "        self.wa = np.random.random((numFeats, 1))\n",
    "        self.ua = np.random.random((1, 1))\n",
    "        self.ba = np.random.random((1, 1))\n",
    "\n",
    "        # input_gate\n",
    "        self.wi = np.random.random((numFeats, 1))\n",
    "        self.ui = np.random.random((1, 1))\n",
    "        self.bi = np.random.random((1, 1))\n",
    "\n",
    "        # forget_gate\n",
    "        self.wf = np.random.random((numFeats, 1))\n",
    "        self.uf = np.random.random((1, 1))\n",
    "        self.bf = np.random.random((1, 1))\n",
    "\n",
    "        # output_gate\n",
    "        self.wo = np.random.random((numFeats, 1))\n",
    "        self.uo = np.random.random((1, 1))\n",
    "        self.bo = np.random.random((1, 1))\n",
    "\n",
    "        # Forward Propogation Parameters\n",
    "        self.prev_input_activation = 0\n",
    "        self.prev_input_gate = 0\n",
    "        self.prev_forget_gate = 0\n",
    "        self.prev_output_gate = 0\n",
    "        \n",
    "        self.input_activation = 0\n",
    "        self.input_gate = 0\n",
    "        self.forget_gate = 0\n",
    "        self.output_gate = 0\n",
    "        self.internal_state = np.zeros((1, 1))\n",
    "        self.output = np.zeros((1, 1))\n",
    "\n",
    "        self.prev_input_activations = []\n",
    "        self.prev_input_gates  = []\n",
    "        self.prev_output_gates  = []\n",
    "        self.prev_forget_gates  = []\n",
    "        self.prev_internal_states  = []\n",
    "        self.prev_outputs = []\n",
    "        \n",
    "        \n",
    "        # Backward Propogation Parameters\n",
    "        self.stacked_ip_weights = []\n",
    "        self.stacked_op_weights = []\n",
    "        \n",
    "        self.der_internal_state_future = np.zeros((1, 1))\n",
    "        self.delta_op_future = np.zeros((1, 1))\n",
    "        \n",
    "        self.input_weight_derivatives = 0\n",
    "        self.output_weight_derivatives = 0\n",
    "        self.bias_derivatives = 0\n",
    "\n",
    "\n",
    "        if self.test:\n",
    "            self.batchSize = 2\n",
    "            self.wa[0]=0.45\n",
    "            self.wa[1]=0.25\n",
    "            self.ua[0]=0.15\n",
    "            self.ba[0]=0.2\n",
    "            self.wi[0]=0.95\n",
    "            self.wi[1]=0.8\n",
    "            self.ui[0]=0.8\n",
    "            self.bi[0]=0.65\n",
    "            self.wf[0]=0.7\n",
    "            self.wf[1]=0.45\n",
    "            self.uf[0]=0.1\n",
    "            self.bf[0]=0.15\n",
    "            self.wo[0]=0.6\n",
    "            self.wo[1]=0.4\n",
    "            self.uo[0]=0.25\n",
    "            self.bo[0]=0.1\n",
    "        \n",
    "    def resetLists(self):\n",
    "        self.prev_input_activations = []\n",
    "        self.prev_input_gates  = []\n",
    "        self.prev_output_gates  = []\n",
    "        self.prev_forget_gates  = []\n",
    "        self.prev_internal_states  = []\n",
    "        self.prev_outputs = []\n",
    "        \n",
    "        # Backward Propogation Parameters\n",
    "        self.stacked_ip_weights = []\n",
    "        self.stacked_op_weights = []\n",
    "\n",
    "    def update_lstmData(self, lr=.01):\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        dip = self.input_weight_derivatives\n",
    "        dop = self.output_weight_derivatives\n",
    "        db = self.bias_derivatives\n",
    "        \n",
    "        t = wa.T - (dip*lr)\n",
    "        wa.T[0] = t[0].T\n",
    "        t = wi.T - (dip*lr)\n",
    "        wi.T[0] = t[1].T\n",
    "        t = wf.T - (dip*lr)\n",
    "        wf.T[0] = t[2].T\n",
    "        t = wo.T - (dip*lr)\n",
    "        wo.T[0] = t[3].T\n",
    "        ua = ua.T - (dop*lr)[0]\n",
    "        ui = ui.T - (dop*lr)[1]\n",
    "        uf = uf.T - (dop*lr)[2]\n",
    "        uo = uo.T - (dop*lr)[3]\n",
    "        ba = ba.T - (db*lr)[0]\n",
    "        bi = bi.T - (db*lr)[1]\n",
    "        bf = bf.T - (db*lr)[2]\n",
    "        bo = bo.T - (db*lr)[3]\n",
    "        self.wa=wa\n",
    "        self.ua=ua\n",
    "        self.ba=ba\n",
    "        self.wi=wi\n",
    "        self.ui=ui\n",
    "        self.bi=bi\n",
    "        self.wf=wf\n",
    "        self.uf=uf\n",
    "        self.bf=bf\n",
    "        self.wo=wo\n",
    "        self.uo=uo\n",
    "        self.bo=bo\n",
    "\n",
    "    def printLSTMparms(self):\n",
    "        lstmData = self.getLSTMparms()\n",
    "        print('wa:', lstmData[0].shape)\n",
    "        print('ua:', lstmData[1].shape)\n",
    "        print('ba:', lstmData[2].shape)\n",
    "        print('wi:', lstmData[3].shape)\n",
    "        print('ui:', lstmData[4].shape)\n",
    "        print('bi:', lstmData[5].shape)\n",
    "        print('wf:', lstmData[6].shape)\n",
    "        print('uf:', lstmData[7].shape)\n",
    "        print('bf:', lstmData[8].shape)\n",
    "        print('wo:', lstmData[9].shape)\n",
    "        print('uo:', lstmData[10].shape)\n",
    "        print('bo:', lstmData[11].shape)\n",
    "\n",
    "\n",
    "        print('wa:', lstmData[0])\n",
    "        print('ua:', lstmData[1])\n",
    "        print('ba:', lstmData[2])\n",
    "        print('wi:', lstmData[3])\n",
    "        print('ui:', lstmData[4])\n",
    "        print('bi:', lstmData[5])\n",
    "        print('wf:', lstmData[6])\n",
    "        print('uf:', lstmData[7])\n",
    "        print('bf:', lstmData[8])\n",
    "        print('wo:', lstmData[9])\n",
    "        print('uo:', lstmData[10])\n",
    "        print('bo:', lstmData[11])\n",
    "\n",
    "    def lstm_data_transform(self):\n",
    "        \"\"\" Changes data to the format for LSTM training \n",
    "    for sliding window approach \"\"\"\n",
    "        # Prepare the list for the transformed data\n",
    "        X, y = list(), list()\n",
    "        # Loop of the entire data set\n",
    "        #print(x_data.shape[0])\n",
    "        for i in range(self.train_data.shape[0]):\n",
    "            # compute a new (sliding window) index\n",
    "            end_ix = i + self.batch_size\n",
    "\n",
    "            # if index is larger than the size of the dataset, we stop\n",
    "            #print(end_ix)\n",
    "            ##TODOOOO - CHANGE BACK TO BELOW AFTER TESTING\n",
    "            #if end_ix >= self.train_data.shape[0]:\n",
    "            if end_ix > self.train_data.shape[0]:\n",
    "                break\n",
    "            # Get a sequence of data for x\n",
    "            seq_X = self.train_data[i:end_ix]\n",
    "            # Get only the last element of the sequency for y\n",
    "            seq_y = self.targets[i:end_ix]\n",
    "            # Append the list with sequencies\n",
    "            X.append(seq_X)\n",
    "            y.append(seq_y)\n",
    "        # Make final arrays\n",
    "        x_array = np.array(X)\n",
    "        y_array = np.array(y)\n",
    "        return x_array, y_array\n",
    "    \n",
    "    def plog(self, *msg, f=0):\n",
    "        if self.debug or f:\n",
    "            print(*msg)\n",
    "        \n",
    "    def getLSTMparms(self):\n",
    "        return self.wa, self.ua, self.ba, self.wi, self.ui, self.bi, self.wf, self.uf, self.bf, self.wo, self.uo, self.bo\n",
    "\n",
    "    def goForward(self, ipt):\n",
    "        #4 gates\n",
    "        # input_activation = tanh(wa [inner] input + ua [inner] prev_output + ba)\n",
    "        # input_gate  = sigmoid(wi [inner] input + ui [inner] prev_output + bi)\n",
    "        # forget_gate = sigmoid(wf [inner] input + uf [inner] prev_output + bf)\n",
    "        # output_gate = sigmoid(wo [inner] input + uo [inner] prev_output + bo)\n",
    "\n",
    "        # 2 states\n",
    "        # internal_state = (input_activation [Element wise] input_gate) + (forget_gate [Element wise] prev_internal_state)\n",
    "        # output = tanh(internal_state) [Element wise] output_gate\n",
    "    \n",
    "        plog = self.plog\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        \n",
    "        po = self.output\n",
    "        ps = self.internal_state\n",
    "        plog(\"wa : \", wa.T)\n",
    "        plog(\"ipt : \", ipt)\n",
    "        plog(\"ua : \", ua)\n",
    "        plog(\"po : \", po)\n",
    "        plog(\"ba : \", ba)\n",
    "\n",
    "        plog(\"ipt T shape\", ipt.T.shape)\n",
    "        plog(\"po shape\", po.shape)\n",
    "            \n",
    "           # print(\"incoming input = \",ippo.T)\n",
    "\n",
    "        input_plus_prev_output = np.row_stack((ipt.T, po))\n",
    "        ippo = input_plus_prev_output\n",
    "\n",
    "            \n",
    "        # input activation\n",
    "        self.input_activation = np.tanh((np.inner(wa.T, ipt)) + (np.inner(ua, po)) + ba)\n",
    "        ia = self.input_activation\n",
    "        self.prev_input_activations.append(ia)\n",
    "\n",
    "        # input gate\n",
    "        self.input_gate = sigmoid((np.inner(wi.T, ipt)) + (np.inner(ui, po)) + bi)\n",
    "        self.prev_input_gates.append(self.input_gate)\n",
    "\n",
    "        # forget gate\n",
    "        self.forget_gate = sigmoid((np.inner(wf.T, ipt)) + (np.inner(uf, po)) + bf)\n",
    "        self.prev_forget_gates.append(self.forget_gate)\n",
    "        \n",
    "        # output gate\n",
    "        self.output_gate = sigmoid((np.inner(wo.T, ipt)) + (np.inner(uo, po)) + bo)\n",
    "        self.prev_output_gates.append(self.output_gate)\n",
    "\n",
    "        # internal state\n",
    "        self.internal_state = (np.multiply(ia, self.input_gate)) + (np.multiply(self.forget_gate, ps))\n",
    "        self.prev_internal_states.append(self.internal_state)\n",
    "\n",
    "        # output\n",
    "        self.output = np.multiply(np.tanh(self.internal_state), self.output_gate)\n",
    "        self.prev_outputs.append(self.output)\n",
    "        \n",
    "        plog(\"input_activation = \",ia)\n",
    "        plog(\"input gate : \", self.input_gate)\n",
    "        plog(\"forget gate : \", self.forget_gate)\n",
    "        plog(\"output gate : \",self.output_gate)\n",
    "        plog(\"internal state\", self.internal_state)\n",
    "        plog(\"output = \",self.output)\n",
    "        plog(\"----------------------------------\")\n",
    "\n",
    "    def stackWeights(self):\n",
    "        stacked_ip_weights = np.copy(self.wa)\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wi))\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wf))\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wo))\n",
    "        self.stacked_ip_weights = stacked_ip_weights\n",
    "        \n",
    "        stacked_op_weights = np.copy(self.ua)\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.ui))\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.uf))\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.uo))\n",
    "        self.stacked_op_weights = stacked_op_weights\n",
    "\n",
    "    def travelBack(self, targets, inputs):\n",
    "\n",
    "        plog = self.plog\n",
    "        # Unpack parameters\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        tempo = np.zeros((1, 1))\n",
    "        plog(\"Targets is\",targets)\n",
    "        plog(\"Inputs is\",inputs)\n",
    "\n",
    "        for t in reversed(range(len(self.prev_outputs))):\n",
    "\n",
    "            output = self.prev_outputs[t]\n",
    "            target = targets[t]\n",
    "            \n",
    "            next_forget_gate = np.zeros((1, 1)) if (t==len(self.prev_outputs)-1) else self.prev_forget_gates[t+1]\n",
    "            \n",
    "            plog(\"previous outputs = \", str(self.prev_outputs))\n",
    "            plog(\"target = \",str(target))\n",
    "            plog(\"output = \", str(output))\n",
    "            \n",
    "            # Track loss\n",
    "            loss = (np.power((target - output),2))/2\n",
    "            plog(\"loss = \", str(loss))\n",
    "\n",
    "            # derivative of loss with respect to output\n",
    "            der_loss_wrt_output = output - target\n",
    "            plog(\"der_loss_wrt_output = \", der_loss_wrt_output)\n",
    "\n",
    "            # derivative of output\n",
    "            der_output = der_loss_wrt_output + self.delta_op_future\n",
    "            plog(\"der_output = \", der_output)\n",
    "\n",
    "            plog(\"der output : \", str(der_output))\n",
    "            plog(\"next state : \", next_state)\n",
    "            plog(\"next forget : \", next_forget)\n",
    "\n",
    "            # derivative of internal state\n",
    "            pog = self.prev_output_gates[t]\n",
    "            ps = self.prev_internal_states[t]\n",
    "            dfis = der_output * pog * (1 - (np.tanh(ps))**2 ) + (self.der_internal_state_future * next_forget_gate)\n",
    "            self.der_internal_state_future = dfis\n",
    "            plog(\"der internal state = \", dfis)\n",
    "            plog(\"pog : \", pog)\n",
    "            plog(\"ps : \", ps)\n",
    "\n",
    "\n",
    "            pig = self.prev_input_gates[t]\n",
    "            pia = self.prev_input_activations[t]\n",
    "            der_input_activation = dfis * pig * (1 - pia**2)\n",
    "            plog(\"der_input_activation = \", der_input_activation)\n",
    "            stacked_ders = np.copy(der_input_activation)\n",
    "\n",
    "            der_inputg = dfis * pia * pig * (1 - pig)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_inputg))\n",
    "            plog(\"der_input = \", der_inputg)\n",
    "\n",
    "            pps = tempo if t==0 else self.prev_internal_states[t-1] \n",
    "            pfg = self.prev_forget_gates[t]\n",
    "            der_forgetg = dfis * pps * pfg * (1 - pfg)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_forgetg))\n",
    "            plog(\"der_forget = \", der_forgetg)   \n",
    "            \n",
    "            plog(\"pps : \", pps, t-1)\n",
    "            plog(\"pfg : \", pfg)\n",
    "            plog(\"dfis : \", str(dfis))\n",
    "\n",
    "            der_outputg = der_output * np.tanh(ps) * pog * (1 - pog)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_outputg))\n",
    "            plog(\"der_output = \", der_outputg)\n",
    "\n",
    "            self.stackWeights()\n",
    "\n",
    "\n",
    "            der_input_state = np.dot(self.stacked_ip_weights, stacked_ders)\n",
    "            plog(\"der_input_state = \", der_input_state)\n",
    "\n",
    "            der_output_state = np.dot(self.stacked_op_weights, stacked_ders)\n",
    "            plog(\"der_output_state = \", der_output_state)\n",
    "            self.delta_op_future = der_output_state\n",
    "\n",
    "            plog(\"inputs t is : \",str(t), np.array([inputs[0][t]]))\n",
    "            der_input_weight = np.dot(stacked_ders, np.array([inputs[0][t]]))\n",
    "            self.input_weight_derivatives += der_input_weight\n",
    "            plog(\"der_input_weight : \", der_input_weight)\n",
    "\n",
    "            po = tempo if t==0 else self.prev_outputs[t-1] \n",
    "            der_op_weight = np.dot(stacked_ders, po)\n",
    "            self.output_weight_derivatives += der_op_weight\n",
    "            plog(\"der_op_weight : \", der_op_weight)\n",
    "\n",
    "            self.bias_derivatives += stacked_ders\n",
    "    \n",
    "    def train(self):\n",
    "        plog = self.plog\n",
    "        ip_batches, op_batches = self.lstm_data_transform()\n",
    "        #print(op_batches)\n",
    "        count = 1\n",
    "        for ipbatch,opbatch in zip(ip_batches, op_batches):\n",
    "            plog(\"Round \"+str(count),\" ipbatch is : \", ipbatch)\n",
    "            plog(\"Round \"+str(count),\" opbatch is : \", opbatch)\n",
    "            for ip in ipbatch:\n",
    "                plog(\"Round \"+str(count),\" ip is \",ip)\n",
    "                self.goForward(np.array([ip]))\n",
    "            self.travelBack(opbatch, np.array([ipbatch]))\n",
    "            self.resetLists()\n",
    "            plog(\"Round \"+str(count),\" Forward and Backward DONE\", f=1)\n",
    "            \n",
    "            plog(\"Round \"+str(count),\" OP DONE\")\n",
    "            plog(\"Round \"+str(count),\" OLD WEIGHTS\")\n",
    "            #self.printLSTMparms()\n",
    "            self.update_lstmData(lr=.01)\n",
    "            plog(\"Round \"+str(count), \" NEW WEIGHTS\")\n",
    "            #self.printLSTMparms()\n",
    "            count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a0af7606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T20:19:59.180289Z",
     "start_time": "2021-11-25T20:19:59.155854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1  Forward and Backward DONE\n",
      "Round 2  Forward and Backward DONE\n",
      "Round 3  Forward and Backward DONE\n",
      "Round 4  Forward and Backward DONE\n"
     ]
    }
   ],
   "source": [
    "#ip = np.array([[1,2],[0.5,3]])\n",
    "#op= np.array([ [0.5],[1.25]])\n",
    "\n",
    "ip = np.array([[1,2],[0.5,3],[1,2],[0.5,3],[1,2],[0.5,3]])\n",
    "op= np.array([ [0.5],[1.25],[0.5],[1.25],[0.5],[1.25] ])\n",
    "\n",
    "lstm = LSTM(train_data=ip, targets=op, batch_size=3, debug=0, test=1)\n",
    "lstm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e039ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec981393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
