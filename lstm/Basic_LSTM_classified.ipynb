{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ef77dc2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:32:41.645732Z",
     "start_time": "2021-11-25T18:32:41.636504Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "f3a7b285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T23:21:16.560082Z",
     "start_time": "2021-11-25T23:21:16.547349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]]\n",
      "--\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "dataset=StringIO(\"\"\"Date,Open,High,Low,Close,Volume,Trade_count,Vwap\n",
    "2015-12-01 09:00:00+00:00,118.88,118.94,118.88,118.94,1145,5,118.902052\n",
    "2015-12-01 09:15:00+00:00,118.77,118.77,118.77,118.77,200,1,118.77\n",
    "2015-12-01 09:30:00+00:00,118.69,118.69,118.6,118.6,900,4,118.61\n",
    "2015-12-01 09:45:00+00:00,118.64,118.65,118.64,118.65,3580,5,118.648883\n",
    "2015-12-01 10:00:00+00:00,118.65,118.65,118.55,118.55,1820,4,118.611538\n",
    "2015-12-01 10:15:00+00:00,118.55,118.6,118.55,118.6,880,5,118.5625\n",
    "2015-12-01 10:30:00+00:00,118.55,118.55,118.5,118.5,1878,5,118.513312\n",
    "2015-12-01 10:45:00+00:00,118.59,118.72,118.59,118.72,2499,10,118.628431\n",
    "2015-12-01 11:00:00+00:00,118.71,118.9,118.71,118.9,2842,11,118.86064\n",
    "2015-12-01 11:15:00+00:00,118.87,118.87,118.87,118.87,300,2,118.87\n",
    "2015-12-01 11:30:00+00:00,118.78,118.8,118.76,118.8,3914,22,118.785876\n",
    "2015-12-01 11:45:00+00:00,118.8,118.99,118.77,118.9,7900,37,118.893542\n",
    "2015-12-01 12:00:00+00:00,118.88,118.98,118.84,118.84,6540,34,118.922648\n",
    "2015-12-01 12:15:00+00:00,118.82,118.84,118.77,118.77,5603,28,118.804962\n",
    "2015-12-01 12:30:00+00:00,118.77,118.89,118.76,118.88,7612,31,118.824002\n",
    "\"\"\")\n",
    "df = pd.read_table(dataset, sep=\",\")\n",
    "\n",
    "#ip = np.array([ [1,2,3],[6,8,9],[3,4,5],[4,7,8],[4,2,5],[5,7,4] ])\n",
    "#op = np.array([[2,8,4,7,2,4]])\n",
    "#op = op.reshape(6,1)\n",
    "ip = np.array([ [1],  [2],  [0],  [2],  [0],  [1],  [2],  [1] ])\n",
    "op = np.array([ [300],[100],[200],[100],[200],[300],[100],[300] ])\n",
    "num_steps = 3\n",
    "num_features = 1\n",
    "#ip_shaped = np.reshape(ip, newshape=(-1, num_steps, num_features))\n",
    "\n",
    "#X = np.array([ [1,2,3, 4, 5, 6] ])\n",
    "#Y = np.array([[2,3,4,5,6,7]])\n",
    "print(ip)\n",
    "print(\"--\")\n",
    "#ip= np.tile(ip,(50,1))\n",
    "#op = np.tile(op,(50,1))\n",
    "print(len(op))\n",
    "#ip = np.array([ [1],[1],[1],[1],[1],[2],[1],[2]])\n",
    "#op = np.array([ [1,    0,    1,    0,    1,    1,    0,    1 ]]).T\n",
    "\n",
    "ip = np.array([ [1,1,2],[1,2,1],[1,0,2],[1,2,1],[1,0,2],[1,1,2],[1,2,1],[1,1,2]])\n",
    "op = np.array([ [10,    20,    10,    20,    10,    10,    20,    10 ]]).T\n",
    "#ip = np.array([ [1,1,1,1,1],[0,2,2,2,2],[1,3,3,3,3],[1,4,4,4,4],[0,5,5,5,5],[0,6,6,6,6],[1,7,7,7,7],[0,8,8,8,8]])\n",
    "#op = np.array([ [1,          0,          1,          1,          0,          0,          1,          0 ]]).T\n",
    "_, numFeats = ip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "8de04139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T23:20:55.133844Z",
     "start_time": "2021-11-25T23:20:55.105077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 3)\n",
      "(93, 3, 3, 1)\n",
      "(3, 3, 1)\n",
      "(93, 3, 1)\n",
      "====\n",
      "[[25]\n",
      " [30]\n",
      " [25]]\n"
     ]
    }
   ],
   "source": [
    "timeSteps = 3\n",
    "ip = np.array([ [1,10,20],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20],\n",
    "               [1,10,45],[1,10,25],[1,10,30],[1,10,25],[1,10,30],[1,10,20],[1,10,25],[1,10,20]            \n",
    "              ])\n",
    "# op = np.array([ [1,         1,         0,         1,         0,         1,         0,         0, \n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0,\n",
    "#                  1,         1,         0,         1,         0,         1,         0,         0\n",
    "#                 ]]).T\n",
    "op = np.array([ [25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45, \n",
    "                 25,       30,       25,       30,       20,       25,       20,       45\n",
    "                ]]).T\n",
    "\n",
    "\n",
    "numFeats = 3\n",
    "# ip = np.array([ [1,1,2],[1,2,1],[1,0,2],[1,2,1],[1,0,2],[1,1,2],[1,2,1],[1,1,2]])\n",
    "# op = np.array([ [0,    0,    0,    0,    0,    0,    0,    0 ]]).T\n",
    "\n",
    "# ip = np.array([ [[1,2],[1,2],[1,2],[2,3]],[[1,2],[1,2],[2,3],[1,2]],\n",
    "#                 [[1,2],[1,2],[0,1],[2,3]],[[1,2],[1,2],[2,3],[1,2]],\n",
    "#                 [[1,2],[1,2],[0,1],[2,3]],[[1,2],[1,2],[1,2],[2,3]],\n",
    "#                 [[1,2],[1,2],[2,3],[1,2]],[[1,2],[1,2],[1,2],[2,3]]])\n",
    "print(ip.shape)\n",
    "ipt,opt=lstm_data_time(ip,op, timeSteps)\n",
    "print(ipt.shape)\n",
    "print(ipt[0].shape)\n",
    "print(opt.shape)\n",
    "\n",
    "print(\"====\")\n",
    "print(opt[0])\n",
    "# batchSize = len(ipt)\n",
    "# [[[1.]\n",
    "#   [0.]\n",
    "#   [0.]]\n",
    "\n",
    "#  [[1.]\n",
    "#   [0.]\n",
    "#   [0.]]\n",
    "\n",
    "#  [[1.]\n",
    "#   [0.]\n",
    "#   [0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "44a26e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:32:41.714640Z",
     "start_time": "2021-11-25T18:32:41.705129Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the element-wise sigmoid activation function for an array x.\n",
    "\n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    f = 1 / (1 + np.exp(-x_safe))\n",
    "    \n",
    "    if derivative: # Return the derivative of the function evaluated at x\n",
    "        return f * (1 - f)\n",
    "    else: # Return the forward pass of the function at x\n",
    "        return f\n",
    "    \n",
    "\n",
    "def update_lstmData(params, dip, dop, db, lr):\n",
    "    wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = params\n",
    "\n",
    "    t = wa.T - (dip*lr)\n",
    "    wa.T[0] = t[0].T\n",
    "    t = wi.T - (dip*lr)\n",
    "    wi.T[0] = t[1].T\n",
    "    t = wf.T - (dip*lr)\n",
    "    wf.T[0] = t[2].T\n",
    "    t = wo.T - (dip*lr)\n",
    "    wo.T[0] = t[3].T\n",
    "    ua = ua.T - (dop*lr)[0]\n",
    "    ui = ui.T - (dop*lr)[1]\n",
    "    uf = uf.T - (dop*lr)[2]\n",
    "    uo = uo.T - (dop*lr)[3]\n",
    "    ba = ba.T - (db*lr)[0]\n",
    "    bi = bi.T - (db*lr)[1]\n",
    "    bf = bf.T - (db*lr)[2]\n",
    "    bo = bo.T - (db*lr)[3]\n",
    "    return wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "7870a92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:20:49.646463Z",
     "start_time": "2021-11-26T00:20:49.515779Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM():\n",
    "    def __init__(self, train_data, targets, batch_size=2, debug=1, test=1):\n",
    "        #4 gates\n",
    "        # input_activation = tanh(wa [inner] input + ua [inner] prev_output + ba)\n",
    "        # input_gate  = sigmoid(wi [inner] input + ui [inner] prev_output + bi)\n",
    "        # forget_gate = sigmoid(wf [inner] input + uf [inner] prev_output + bf)\n",
    "        # output_gate = sigmoid(wo [inner] input + uo [inner] prev_output + bo)\n",
    "\n",
    "        # 2 states\n",
    "        # internal_state = (input_activation [Element wise] input_gate) + (forget_gate [Element wise] prev_internal_state)\n",
    "        # output = tanh(internal_state) [Element wise] output_gate\n",
    "\n",
    "        if batch_size >= len(train_data):\n",
    "            print(f'Batch Size {batch_size} should be less than the size of the dataset {len(train_data)}')\n",
    "            return None\n",
    "        \n",
    "        # To enable test mode. Batch size would be set as 2\n",
    "        self.test = test\n",
    "        \n",
    "        # The number of records that would go inside the LSTM at one time. A sequence of records.\n",
    "        self.batch_size = batch_size\n",
    "        numFeats = train_data.shape[1] ###### CHANGE IT TO GET DYNAMICALLY FROM INPUT\n",
    "        # Enable debug logs\n",
    "        self.debug = debug\n",
    "        \n",
    "        # Training Data\n",
    "        self.train_data = train_data\n",
    "        # Target of training data\n",
    "        self.targets = targets\n",
    "        \n",
    "        \n",
    "        # input_activation\n",
    "        self.wa = np.random.random((numFeats, 1))\n",
    "        self.ua = np.random.random((1, 1))\n",
    "        self.ba = np.random.random((1, 1))\n",
    "\n",
    "        # input_gate\n",
    "        self.wi = np.random.random((numFeats, 1))\n",
    "        self.ui = np.random.random((1, 1))\n",
    "        self.bi = np.random.random((1, 1))\n",
    "\n",
    "        # forget_gate\n",
    "        self.wf = np.random.random((numFeats, 1))\n",
    "        self.uf = np.random.random((1, 1))\n",
    "        self.bf = np.random.random((1, 1))\n",
    "\n",
    "        # output_gate\n",
    "        self.wo = np.random.random((numFeats, 1))\n",
    "        self.uo = np.random.random((1, 1))\n",
    "        self.bo = np.random.random((1, 1))\n",
    "\n",
    "        # Clean and init LSTM\n",
    "        self.cleanLSTM()\n",
    "\n",
    "\n",
    "        if self.test:\n",
    "            self.batchSize = 1\n",
    "            self.wa[0]=0.45\n",
    "            self.wa[1]=0.25\n",
    "            self.ua[0]=0.15\n",
    "            self.ba[0]=0.2\n",
    "            self.wi[0]=0.95\n",
    "            self.wi[1]=0.8\n",
    "            self.ui[0]=0.8\n",
    "            self.bi[0]=0.65\n",
    "            self.wf[0]=0.7\n",
    "            self.wf[1]=0.45\n",
    "            self.uf[0]=0.1\n",
    "            self.bf[0]=0.15\n",
    "            self.wo[0]=0.6\n",
    "            self.wo[1]=0.4\n",
    "            self.uo[0]=0.25\n",
    "            self.bo[0]=0.1\n",
    "        \n",
    "    def cleanLSTM(self):\n",
    "        # Forward Propogation Parameters\n",
    "        self.prev_input_activation = 0\n",
    "        self.prev_input_gate = 0\n",
    "        self.prev_forget_gate = 0\n",
    "        self.prev_output_gate = 0\n",
    "        \n",
    "        self.input_activation = 0\n",
    "        self.input_gate = 0\n",
    "        self.forget_gate = 0\n",
    "        self.output_gate = 0\n",
    "        self.internal_state = np.zeros((1, 1))\n",
    "        self.output = np.zeros((1, 1))\n",
    "\n",
    "        self.prev_input_activations = []\n",
    "        self.prev_input_gates  = []\n",
    "        self.prev_output_gates  = []\n",
    "        self.prev_forget_gates  = []\n",
    "        self.prev_internal_states  = []\n",
    "        self.prev_outputs = []\n",
    "        \n",
    "        \n",
    "        # Backward Propogation Parameters\n",
    "        self.stacked_ip_weights = []\n",
    "        self.stacked_op_weights = []\n",
    "        \n",
    "        self.der_internal_state_future = np.zeros((1, 1))\n",
    "        self.delta_op_future = np.zeros((1, 1))\n",
    "        \n",
    "        self.input_weight_derivatives = 0\n",
    "        self.output_weight_derivatives = 0\n",
    "        self.bias_derivatives = 0\n",
    "\n",
    "    def update_lstmData(self, lr=.01):\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        dip = self.input_weight_derivatives\n",
    "        dop = self.output_weight_derivatives\n",
    "        db = self.bias_derivatives\n",
    "        \n",
    "        t = wa.T - (dip*lr)\n",
    "        wa.T[0] = t[0].T\n",
    "        t = wi.T - (dip*lr)\n",
    "        wi.T[0] = t[1].T\n",
    "        t = wf.T - (dip*lr)\n",
    "        wf.T[0] = t[2].T\n",
    "        t = wo.T - (dip*lr)\n",
    "        wo.T[0] = t[3].T\n",
    "        ua = ua.T - (dop*lr)[0]\n",
    "        ui = ui.T - (dop*lr)[1]\n",
    "        uf = uf.T - (dop*lr)[2]\n",
    "        uo = uo.T - (dop*lr)[3]\n",
    "        ba = ba.T - (db*lr)[0]\n",
    "        bi = bi.T - (db*lr)[1]\n",
    "        bf = bf.T - (db*lr)[2]\n",
    "        bo = bo.T - (db*lr)[3]\n",
    "        self.wa=wa\n",
    "        self.ua=ua\n",
    "        self.ba=ba\n",
    "        self.wi=wi\n",
    "        self.ui=ui\n",
    "        self.bi=bi\n",
    "        self.wf=wf\n",
    "        self.uf=uf\n",
    "        self.bf=bf\n",
    "        self.wo=wo\n",
    "        self.uo=uo\n",
    "        self.bo=bo\n",
    "\n",
    "    def printLSTMparms(self):\n",
    "        lstmData = self.getLSTMparms()\n",
    "        print('wa:', lstmData[0].shape)\n",
    "        print('ua:', lstmData[1].shape)\n",
    "        print('ba:', lstmData[2].shape)\n",
    "        print('wi:', lstmData[3].shape)\n",
    "        print('ui:', lstmData[4].shape)\n",
    "        print('bi:', lstmData[5].shape)\n",
    "        print('wf:', lstmData[6].shape)\n",
    "        print('uf:', lstmData[7].shape)\n",
    "        print('bf:', lstmData[8].shape)\n",
    "        print('wo:', lstmData[9].shape)\n",
    "        print('uo:', lstmData[10].shape)\n",
    "        print('bo:', lstmData[11].shape)\n",
    "\n",
    "\n",
    "        print('wa:', lstmData[0])\n",
    "        print('ua:', lstmData[1])\n",
    "        print('ba:', lstmData[2])\n",
    "        print('wi:', lstmData[3])\n",
    "        print('ui:', lstmData[4])\n",
    "        print('bi:', lstmData[5])\n",
    "        print('wf:', lstmData[6])\n",
    "        print('uf:', lstmData[7])\n",
    "        print('bf:', lstmData[8])\n",
    "        print('wo:', lstmData[9])\n",
    "        print('uo:', lstmData[10])\n",
    "        print('bo:', lstmData[11])\n",
    "\n",
    "    def lstm_data_transform(self, ip=None):\n",
    "        \"\"\" Changes data to the format for LSTM training \n",
    "    for sliding window approach \"\"\"\n",
    "        # Prepare the list for the transformed data\n",
    "        X, y = list(), list()\n",
    "        if ip is not None:\n",
    "            data = ip\n",
    "        else:\n",
    "            data = self.train_data\n",
    "        # Loop of the entire data set\n",
    "        for i in range(data.shape[0]):\n",
    "            # compute a new (sliding window) index\n",
    "            end_ix = i + self.batch_size\n",
    "\n",
    "            # if index is larger than the size of the dataset, we stop\n",
    "            if end_ix >= data.shape[0]:\n",
    "                break\n",
    "            # Get a sequence of data for x\n",
    "            seq_X = data[i:end_ix]\n",
    "            # Get only the last element of the sequency for y\n",
    "            seq_y = self.targets[i:end_ix]\n",
    "            # Append the list with sequencies\n",
    "            X.append(seq_X)\n",
    "            y.append(seq_y)\n",
    "        # Make final arrays\n",
    "        x_array = np.array(X)\n",
    "        y_array = np.array(y)\n",
    "        return x_array, y_array\n",
    "    \n",
    "    def plog(self, *msg, f=0):\n",
    "        if self.debug or f:\n",
    "            print(*msg)\n",
    "\n",
    "    def setLSTMparms(self, parms):\n",
    "        self.wa, self.ua, self.ba, self.wi, self.ui, self.bi, self.wf, self.uf, self.bf, self.wo, self.uo, self.bo = parms\n",
    "        \n",
    "    def getLSTMparms(self):\n",
    "        return self.wa, self.ua, self.ba, self.wi, self.ui, self.bi, self.wf, self.uf, self.bf, self.wo, self.uo, self.bo\n",
    "\n",
    "    def goForward(self, ipt, train=1):\n",
    "        #4 gates\n",
    "        # input_activation = tanh(wa [inner] input + ua [inner] prev_output + ba)\n",
    "        # input_gate  = sigmoid(wi [inner] input + ui [inner] prev_output + bi)\n",
    "        # forget_gate = sigmoid(wf [inner] input + uf [inner] prev_output + bf)\n",
    "        # output_gate = sigmoid(wo [inner] input + uo [inner] prev_output + bo)\n",
    "\n",
    "        # 2 states\n",
    "        # internal_state = (input_activation [Element wise] input_gate) + (forget_gate [Element wise] prev_internal_state)\n",
    "        # output = tanh(internal_state) [Element wise] output_gate\n",
    "    \n",
    "        plog = self.plog\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        \n",
    "        po = self.output\n",
    "        ps = self.internal_state\n",
    "        plog(\"wa : \", wa.T)\n",
    "        plog(\"ipt : \", ipt)\n",
    "        plog(\"ua : \", ua)\n",
    "        plog(\"po : \", po)\n",
    "        plog(\"ba : \", ba)\n",
    "\n",
    "        plog(\"ipt T shape\", ipt.T.shape)\n",
    "        plog(\"po shape\", po.shape)\n",
    "            \n",
    "           # print(\"incoming input = \",ippo.T)\n",
    "\n",
    "        input_plus_prev_output = np.row_stack((ipt.T, po))\n",
    "        ippo = input_plus_prev_output\n",
    "\n",
    "            \n",
    "        # input activation\n",
    "        self.input_activation = np.tanh((np.inner(wa.T, ipt)) + (np.inner(ua, po)) + ba)\n",
    "        ia = self.input_activation\n",
    "\n",
    "        # input gate\n",
    "        self.input_gate = sigmoid((np.inner(wi.T, ipt)) + (np.inner(ui, po)) + bi)\n",
    "\n",
    "        # forget gate\n",
    "        self.forget_gate = sigmoid((np.inner(wf.T, ipt)) + (np.inner(uf, po)) + bf)\n",
    "        \n",
    "        # output gate\n",
    "        self.output_gate = sigmoid((np.inner(wo.T, ipt)) + (np.inner(uo, po)) + bo)\n",
    "\n",
    "        # internal state\n",
    "        self.internal_state = (np.multiply(ia, self.input_gate)) + (np.multiply(self.forget_gate, ps))\n",
    "\n",
    "        # output\n",
    "        self.output = np.multiply(np.tanh(self.internal_state), self.output_gate)\n",
    "        \n",
    "        if train:\n",
    "            self.prev_input_activations.append(ia)\n",
    "            self.prev_input_gates.append(self.input_gate)\n",
    "            self.prev_forget_gates.append(self.forget_gate)\n",
    "            self.prev_output_gates.append(self.output_gate)\n",
    "            self.prev_internal_states.append(self.internal_state)\n",
    "            self.prev_outputs.append(self.output)\n",
    "\n",
    "        plog(\"input_activation = \",ia)\n",
    "        plog(\"input gate : \", self.input_gate)\n",
    "        plog(\"forget gate : \", self.forget_gate)\n",
    "        plog(\"output gate : \",self.output_gate)\n",
    "        plog(\"internal state\", self.internal_state)\n",
    "        plog(\"output = \",self.output)\n",
    "        plog(\"----------------------------------\")\n",
    "        return self.output\n",
    "        \n",
    "    def stackWeights(self):\n",
    "        stacked_ip_weights = np.copy(self.wa)\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wi))\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wf))\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wo))\n",
    "        self.stacked_ip_weights = stacked_ip_weights\n",
    "        \n",
    "        stacked_op_weights = np.copy(self.ua)\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.ui))\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.uf))\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.uo))\n",
    "        self.stacked_op_weights = stacked_op_weights\n",
    "\n",
    "    def travelBack(self, targets, inputs):\n",
    "\n",
    "        plog = self.plog\n",
    "        # Unpack parameters\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        tempo = np.zeros((1, 1))\n",
    "        loss=0\n",
    "        plog(\"Targets is\",targets)\n",
    "        plog(\"Inputs is\",inputs)\n",
    "\n",
    "        for t in reversed(range(len(self.prev_outputs))):\n",
    "\n",
    "            output = self.prev_outputs[t]\n",
    "            target = targets[t]\n",
    "            \n",
    "            next_forget_gate = np.zeros((1, 1)) if (t==len(self.prev_outputs)-1) else self.prev_forget_gates[t+1]\n",
    "            \n",
    "            plog(\"previous outputs = \", str(self.prev_outputs))\n",
    "            plog(\"target = \",str(target))\n",
    "            plog(\"output = \", str(output))\n",
    "            \n",
    "            # Track loss\n",
    "            loss = (np.power((target - output),2))/2\n",
    "            plog(\"loss = \", str(loss), f=0)\n",
    "\n",
    "            # derivative of loss with respect to output\n",
    "            der_loss_wrt_output = output - target\n",
    "            plog(\"der_loss_wrt_output = \", der_loss_wrt_output)\n",
    "\n",
    "            # derivative of output\n",
    "            der_output = der_loss_wrt_output + self.delta_op_future\n",
    "            plog(\"der_output = \", der_output)\n",
    "\n",
    "            plog(\"der output : \", str(der_output))\n",
    "            plog(\"next state : \", next_state)\n",
    "            plog(\"next forget : \", next_forget)\n",
    "\n",
    "            # derivative of internal state\n",
    "            pog = self.prev_output_gates[t]\n",
    "            ps = self.prev_internal_states[t]\n",
    "            dfis = der_output * pog * (1 - (np.tanh(ps))**2 ) + (self.der_internal_state_future * next_forget_gate)\n",
    "            self.der_internal_state_future = dfis\n",
    "            plog(\"der internal state = \", dfis)\n",
    "            plog(\"pog : \", pog)\n",
    "            plog(\"ps : \", ps)\n",
    "\n",
    "\n",
    "            pig = self.prev_input_gates[t]\n",
    "            pia = self.prev_input_activations[t]\n",
    "            der_input_activation = dfis * pig * (1 - pia**2)\n",
    "            plog(\"der_input_activation = \", der_input_activation)\n",
    "            stacked_ders = np.copy(der_input_activation)\n",
    "\n",
    "            der_inputg = dfis * pia * pig * (1 - pig)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_inputg))\n",
    "            plog(\"der_input = \", der_inputg)\n",
    "\n",
    "            pps = tempo if t==0 else self.prev_internal_states[t-1] \n",
    "            pfg = self.prev_forget_gates[t]\n",
    "            der_forgetg = dfis * pps * pfg * (1 - pfg)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_forgetg))\n",
    "            plog(\"der_forget = \", der_forgetg)   \n",
    "            \n",
    "            plog(\"pps : \", pps, t-1)\n",
    "            plog(\"pfg : \", pfg)\n",
    "            plog(\"dfis : \", str(dfis))\n",
    "\n",
    "            der_outputg = der_output * np.tanh(ps) * pog * (1 - pog)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_outputg))\n",
    "            plog(\"der_output = \", der_outputg)\n",
    "\n",
    "            self.stackWeights()\n",
    "\n",
    "\n",
    "            der_input_state = np.dot(self.stacked_ip_weights, stacked_ders)\n",
    "            plog(\"der_input_state = \", der_input_state)\n",
    "\n",
    "            der_output_state = np.dot(self.stacked_op_weights, stacked_ders)\n",
    "            plog(\"der_output_state = \", der_output_state)\n",
    "            self.delta_op_future = der_output_state\n",
    "\n",
    "            plog(\"inputs t is : \",str(t), np.array([inputs[0][t]]))\n",
    "            der_input_weight = np.dot(stacked_ders, np.array([inputs[0][t]]))\n",
    "            self.input_weight_derivatives += der_input_weight\n",
    "            plog(\"der_input_weight : \", der_input_weight)\n",
    "\n",
    "            po = tempo if t==0 else self.prev_outputs[t-1] \n",
    "            der_op_weight = np.dot(stacked_ders, po)\n",
    "            self.output_weight_derivatives += der_op_weight\n",
    "            plog(\"der_op_weight : \", der_op_weight)\n",
    "\n",
    "            self.bias_derivatives += stacked_ders\n",
    "        return loss\n",
    "    \n",
    "    def train(self, epoch=2, lr=.01):\n",
    "        plog = self.plog\n",
    "        ip_batches, op_batches = self.lstm_data_transform()\n",
    "        #print(op_batches)\n",
    "        count = 1\n",
    "        for runit in range (epoch):\n",
    "            plog(\"Running EPOCH \", runit+1, f=0)\n",
    "\n",
    "            for ipbatch,opbatch in zip(ip_batches, op_batches):\n",
    "                self.cleanLSTM()\n",
    "                plog(\"Round \"+str(count),\" ipbatch is : \", ipbatch)\n",
    "                plog(\"Round \"+str(count),\" opbatch is : \", opbatch)\n",
    "                for ip in ipbatch:\n",
    "                    plog(\"Round \"+str(count),\" ip is \",ip)\n",
    "                    self.goForward(np.array([ip]))\n",
    "                loss = self.travelBack(opbatch, np.array([ipbatch]))\n",
    "                plog(\"Round \"+str(count),\" Forward and Backward DONE\", f=0)\n",
    "                plog(\"Round \"+str(count),\" OP DONE\")\n",
    "                plog(\"Round \"+str(count),\" OLD WEIGHTS\")\n",
    "                #self.printLSTMparms()\n",
    "                self.update_lstmData(lr)\n",
    "                plog(\"Round \"+str(count), \" NEW WEIGHTS\")\n",
    "                #self.printLSTMparms()\n",
    "                count+=1\n",
    "            if runit % 100 ==0:\n",
    "                print(\"loss at epoch\",runit,\"is \", loss)\n",
    "    \n",
    "    def goPredict(self, inputs, opscaler=None, ipscaler=None):\n",
    "        plog = self.plog\n",
    "        ip_batches, _ = self.lstm_data_transform(inputs)\n",
    "        count = 1\n",
    "\n",
    "        for ipbatch in ip_batches:\n",
    "            self.cleanLSTM()\n",
    "            plog(\"Round \"+str(count),\" ipbatch is : \", ipbatch)\n",
    "\n",
    "            for ip in ipbatch:\n",
    "                plog(\"Round \"+str(count),\" ip is \",ip)\n",
    "                output = self.goForward(np.array([ip]), train=0)\n",
    "                if ipscaler and opscaler:\n",
    "                    print(f'Current Price : {round(ipscaler.inverse_transform(np.array([ip]))[0][0],3)} \\\n",
    "                            Next Price : {round(opscaler.inverse_transform(output)[0][0], 3)} \\n')\n",
    "                else:\n",
    "                    print(f'For input {ip} \\n output is {output}')\n",
    "\n",
    "            count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "3bdc40a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T23:32:28.049064Z",
     "start_time": "2021-11-25T23:32:28.007908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is  [[0.07651088]]\n"
     ]
    }
   ],
   "source": [
    "ip = np.array([[1,2],[0.5,3]])\n",
    "op= np.array([ [0.5],[1.25]])\n",
    "\n",
    "ip = np.array([[1,2],[0.5,3],[1,2],[0.5,3],[1,2],[0.5,3]])\n",
    "op= np.array([ [0.2],[0.8],[0.2],[0.8],[0.2],[0.8] ])\n",
    "\n",
    "lstm = LSTM(train_data=ip, targets=op, batch_size=2, debug=0, test=0)\n",
    "lstm.train(epoch=3, lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "67c40fe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T23:32:32.247190Z",
     "start_time": "2021-11-25T23:32:32.231572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For input [1. 2.] output is [[0.41455256]]\n",
      "For input [0.5 3. ] output is [[0.63719409]]\n",
      "For input [0.5 3. ] output is [[0.39357069]]\n",
      "For input [1. 2.] output is [[0.63323073]]\n",
      "For input [1. 2.] output is [[0.41455256]]\n",
      "For input [0.5 3. ] output is [[0.63719409]]\n",
      "For input [0.5 3. ] output is [[0.39357069]]\n",
      "For input [1. 2.] output is [[0.63323073]]\n"
     ]
    }
   ],
   "source": [
    "ip = np.array([[1,2],[0.5,3],[1,2],[0.5,3],[1,2],[0.5,3]])\n",
    "op= np.array([ [0.5],[1.25],[0.5],[1.25],[0.5],[1.25] ])\n",
    "\n",
    "lstm.goPredict(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "36e489e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:20:23.880614Z",
     "start_time": "2021-11-26T00:20:23.838181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Trade_count</th>\n",
       "      <th>Vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122727</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.949684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.236207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.438961</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.331197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.239964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.088312</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.120165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217922</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.298571</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.281234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.343117</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.848516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.871382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.482338</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.665869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.823377</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.701688</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.712495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.962597</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.759010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open      High       Low     Close    Volume  Trade_count      Vwap\n",
       "0   1.000000  0.886364  1.000000  1.000000  0.122727     0.111111  0.949684\n",
       "1   0.666667  0.500000  0.710526  0.613636  0.000000     0.000000  0.627084\n",
       "2   0.424242  0.318182  0.263158  0.227273  0.090909     0.083333  0.236207\n",
       "3   0.272727  0.227273  0.368421  0.340909  0.438961     0.111111  0.331197\n",
       "4   0.303030  0.227273  0.131579  0.113636  0.210390     0.083333  0.239964\n",
       "5   0.000000  0.113636  0.131579  0.227273  0.088312     0.111111  0.120165\n",
       "6   0.000000  0.000000  0.000000  0.000000  0.217922     0.111111  0.000000\n",
       "7   0.121212  0.386364  0.236842  0.500000  0.298571     0.250000  0.281234\n",
       "8   0.484848  0.795455  0.552632  0.909091  0.343117     0.277778  0.848516\n",
       "9   0.969697  0.727273  0.973684  0.840909  0.012987     0.027778  0.871382\n",
       "10  0.696970  0.568182  0.684211  0.681818  0.482338     0.583333  0.665869\n",
       "11  0.757576  1.000000  0.710526  0.909091  1.000000     1.000000  0.928895\n",
       "12  1.000000  0.977273  0.894737  0.772727  0.823377     0.916667  1.000000\n",
       "13  0.818182  0.659091  0.710526  0.613636  0.701688     0.750000  0.712495\n",
       "14  0.666667  0.772727  0.684211  0.863636  0.962597     0.833333  0.759010"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def add_target(sf):\n",
    "    ts=sf[\"Open\"]\n",
    "    sf[\"target\"]=target_list[1:].reset_index(drop=True)\n",
    "\n",
    "opscaler = MinMaxScaler()\n",
    "ipscaler = MinMaxScaler()\n",
    "sf=df.copy()\n",
    "sf.drop(\"Date\", axis=1, inplace=True)\n",
    "ts = sf.filter([\"Open\"], axis=1)\n",
    "ts.columns = ['target']\n",
    "ts[\"target\"]=ts['target'][1:].reset_index(drop=True)\n",
    "sf[['Open','High','Low','Close','Volume','Trade_count','Vwap']] = ipscaler.fit_transform(sf[['Open','High','Low','Close','Volume','Trade_count','Vwap']])\n",
    "ts[['target']] = opscaler.fit_transform(ts[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "d4561006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:24:13.475835Z",
     "start_time": "2021-11-26T00:21:47.630728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "loss at epoch 0 is  [[0.00869184]]\n",
      "loss at epoch 100 is  [[0.00116575]]\n",
      "loss at epoch 200 is  [[0.00120005]]\n",
      "loss at epoch 300 is  [[0.00132891]]\n",
      "loss at epoch 400 is  [[0.00107145]]\n",
      "loss at epoch 500 is  [[0.00072135]]\n",
      "loss at epoch 600 is  [[0.00054349]]\n",
      "loss at epoch 700 is  [[0.00047424]]\n",
      "loss at epoch 800 is  [[0.00045641]]\n",
      "loss at epoch 900 is  [[0.00046413]]\n",
      "loss at epoch 1000 is  [[0.00048515]]\n",
      "loss at epoch 1100 is  [[0.00051264]]\n",
      "loss at epoch 1200 is  [[0.00054231]]\n",
      "loss at epoch 1300 is  [[0.00057138]]\n",
      "loss at epoch 1400 is  [[0.00059815]]\n",
      "loss at epoch 1500 is  [[0.00062175]]\n",
      "loss at epoch 1600 is  [[0.00064187]]\n",
      "loss at epoch 1700 is  [[0.00065861]]\n",
      "loss at epoch 1800 is  [[0.00067227]]\n",
      "loss at epoch 1900 is  [[0.00068326]]\n",
      "loss at epoch 2000 is  [[0.00069197]]\n",
      "loss at epoch 2100 is  [[0.0006988]]\n",
      "loss at epoch 2200 is  [[0.00070407]]\n",
      "loss at epoch 2300 is  [[0.00070807]]\n",
      "loss at epoch 2400 is  [[0.00071103]]\n",
      "loss at epoch 2500 is  [[0.00071314]]\n",
      "loss at epoch 2600 is  [[0.00071454]]\n",
      "loss at epoch 2700 is  [[0.00071537]]\n",
      "loss at epoch 2800 is  [[0.00071571]]\n",
      "loss at epoch 2900 is  [[0.00071564]]\n",
      "loss at epoch 3000 is  [[0.00071523]]\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(train_data=sf, targets=ts, batch_size=4, debug=0, test=0)\n",
    "lstm.train(epoch=3001, lr=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "e13a6dbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:24:17.678644Z",
     "start_time": "2021-11-26T00:24:17.638740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Price : 118.88                             Next Price : 118.798 \n",
      "\n",
      "Current Price : 118.77                             Next Price : 118.69 \n",
      "\n",
      "Current Price : 118.69                             Next Price : 118.647 \n",
      "\n",
      "Current Price : 118.64                             Next Price : 118.653 \n",
      "\n",
      "Current Price : 118.77                             Next Price : 118.696 \n",
      "\n",
      "Current Price : 118.69                             Next Price : 118.635 \n",
      "\n",
      "Current Price : 118.64                             Next Price : 118.654 \n",
      "\n",
      "Current Price : 118.65                             Next Price : 118.55 \n",
      "\n",
      "Current Price : 118.69                             Next Price : 118.639 \n",
      "\n",
      "Current Price : 118.64                             Next Price : 118.649 \n",
      "\n",
      "Current Price : 118.65                             Next Price : 118.551 \n",
      "\n",
      "Current Price : 118.55                             Next Price : 118.554 \n",
      "\n",
      "Current Price : 118.64                             Next Price : 118.649 \n",
      "\n",
      "Current Price : 118.65                             Next Price : 118.55 \n",
      "\n",
      "Current Price : 118.55                             Next Price : 118.554 \n",
      "\n",
      "Current Price : 118.55                             Next Price : 118.55 \n",
      "\n",
      "Current Price : 118.65                             Next Price : 118.557 \n",
      "\n",
      "Current Price : 118.55                             Next Price : 118.554 \n",
      "\n",
      "Current Price : 118.55                             Next Price : 118.55 \n",
      "\n",
      "Current Price : 118.59                             Next Price : 118.713 \n",
      "\n",
      "Current Price : 118.55                             Next Price : 118.554 \n",
      "\n",
      "Current Price : 118.55                             Next Price : 118.55 \n",
      "\n",
      "Current Price : 118.59                             Next Price : 118.713 \n",
      "\n",
      "Current Price : 118.71                             Next Price : 118.85 \n",
      "\n",
      "Current Price : 118.55                             Next Price : 118.55 \n",
      "\n",
      "Current Price : 118.59                             Next Price : 118.713 \n",
      "\n",
      "Current Price : 118.71                             Next Price : 118.85 \n",
      "\n",
      "Current Price : 118.87                             Next Price : 118.778 \n",
      "\n",
      "Current Price : 118.59                             Next Price : 118.713 \n",
      "\n",
      "Current Price : 118.71                             Next Price : 118.85 \n",
      "\n",
      "Current Price : 118.87                             Next Price : 118.778 \n",
      "\n",
      "Current Price : 118.78                             Next Price : 118.809 \n",
      "\n",
      "Current Price : 118.71                             Next Price : 118.801 \n",
      "\n",
      "Current Price : 118.87                             Next Price : 118.788 \n",
      "\n",
      "Current Price : 118.78                             Next Price : 118.804 \n",
      "\n",
      "Current Price : 118.8                             Next Price : 118.875 \n",
      "\n",
      "Current Price : 118.87                             Next Price : 118.776 \n",
      "\n",
      "Current Price : 118.78                             Next Price : 118.799 \n",
      "\n",
      "Current Price : 118.8                             Next Price : 118.873 \n",
      "\n",
      "Current Price : 118.88                             Next Price : 118.823 \n",
      "\n",
      "Current Price : 118.78                             Next Price : 118.788 \n",
      "\n",
      "Current Price : 118.8                             Next Price : 118.864 \n",
      "\n",
      "Current Price : 118.88                             Next Price : 118.824 \n",
      "\n",
      "Current Price : 118.82                             Next Price : 118.766 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm.goPredict(sf, opscaler, ipscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ea7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
