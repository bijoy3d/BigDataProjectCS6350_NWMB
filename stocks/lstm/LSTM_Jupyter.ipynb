{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ef77dc2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T02:24:48.745633Z",
     "start_time": "2021-11-26T02:24:48.736860Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a7b285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T01:22:30.615792Z",
     "start_time": "2021-11-26T01:22:30.605538Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset=StringIO(\"\"\"Date,Open,High,Low,Close,Volume,Trade_count,Vwap\n",
    "2015-12-01 09:00:00+00:00,118.88,118.94,118.88,118.94,1145,5,118.902052\n",
    "2015-12-01 09:15:00+00:00,118.77,118.77,118.77,118.77,200,1,118.77\n",
    "2015-12-01 09:30:00+00:00,118.69,118.69,118.6,118.6,900,4,118.61\n",
    "2015-12-01 09:45:00+00:00,118.64,118.65,118.64,118.65,3580,5,118.648883\n",
    "2015-12-01 10:00:00+00:00,118.65,118.65,118.55,118.55,1820,4,118.611538\n",
    "2015-12-01 10:15:00+00:00,118.55,118.6,118.55,118.6,880,5,118.5625\n",
    "2015-12-01 10:30:00+00:00,118.55,118.55,118.5,118.5,1878,5,118.513312\n",
    "2015-12-01 10:45:00+00:00,118.59,118.72,118.59,118.72,2499,10,118.628431\n",
    "2015-12-01 11:00:00+00:00,118.71,118.9,118.71,118.9,2842,11,118.86064\n",
    "2015-12-01 11:15:00+00:00,118.87,118.87,118.87,118.87,300,2,118.87\n",
    "2015-12-01 11:30:00+00:00,118.78,118.8,118.76,118.8,3914,22,118.785876\n",
    "2015-12-01 11:45:00+00:00,118.8,118.99,118.77,118.9,7900,37,118.893542\n",
    "2015-12-01 12:00:00+00:00,118.88,118.98,118.84,118.84,6540,34,118.922648\n",
    "2015-12-01 12:15:00+00:00,118.82,118.84,118.77,118.77,5603,28,118.804962\n",
    "2015-12-01 12:30:00+00:00,118.77,118.89,118.76,118.88,7612,31,118.824002\n",
    "\"\"\")\n",
    "df = pd.read_table(dataset, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a26e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T01:22:30.627558Z",
     "start_time": "2021-11-26T01:22:30.618039Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Computes the element-wise sigmoid activation function for an array x.\n",
    "\n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    return 1 / (1 + np.exp(-x_safe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7870a92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T02:28:59.658578Z",
     "start_time": "2021-11-26T02:28:59.575739Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM():\n",
    "    def __init__(self, train_data, targets, batch_size=2, debug=1, test=1):\n",
    "        #4 gates\n",
    "        # input_activation = tanh(wa [inner] input + ua [inner] prev_output + ba)\n",
    "        # input_gate  = sigmoid(wi [inner] input + ui [inner] prev_output + bi)\n",
    "        # forget_gate = sigmoid(wf [inner] input + uf [inner] prev_output + bf)\n",
    "        # output_gate = sigmoid(wo [inner] input + uo [inner] prev_output + bo)\n",
    "\n",
    "        # 2 states\n",
    "        # internal_state = (input_activation [Element wise] input_gate) + (forget_gate [Element wise] prev_internal_state)\n",
    "        # output = tanh(internal_state) [Element wise] output_gate\n",
    "\n",
    "        if batch_size >= len(train_data):\n",
    "            print(f'Batch Size {batch_size} should be less than the size of the dataset {len(train_data)}')\n",
    "            return None\n",
    "        \n",
    "        # To enable test mode. Batch size would be set as 2\n",
    "        self.test = test\n",
    "        \n",
    "        # The number of records that would go inside the LSTM at one time. A sequence of records.\n",
    "        self.batch_size = batch_size\n",
    "        numFeats = train_data.shape[1] ###### CHANGE IT TO GET DYNAMICALLY FROM INPUT\n",
    "        # Enable debug logs\n",
    "        self.debug = debug\n",
    "        \n",
    "        # Training Data\n",
    "        self.train_data = train_data\n",
    "        # Target of training data\n",
    "        self.targets = targets\n",
    "        \n",
    "        \n",
    "        # input_activation\n",
    "        self.wa = np.random.random((numFeats, 1))\n",
    "        self.ua = np.random.random((1, 1))\n",
    "        self.ba = np.random.random((1, 1))\n",
    "\n",
    "        # input_gate\n",
    "        self.wi = np.random.random((numFeats, 1))\n",
    "        self.ui = np.random.random((1, 1))\n",
    "        self.bi = np.random.random((1, 1))\n",
    "\n",
    "        # forget_gate\n",
    "        self.wf = np.random.random((numFeats, 1))\n",
    "        self.uf = np.random.random((1, 1))\n",
    "        self.bf = np.random.random((1, 1))\n",
    "\n",
    "        # output_gate\n",
    "        self.wo = np.random.random((numFeats, 1))\n",
    "        self.uo = np.random.random((1, 1))\n",
    "        self.bo = np.random.random((1, 1))\n",
    "\n",
    "        # Clean and init LSTM\n",
    "        self.cleanLSTM()\n",
    "\n",
    "\n",
    "        if self.test:\n",
    "            self.batchSize = 1\n",
    "            self.wa[0]=0.45\n",
    "            self.wa[1]=0.25\n",
    "            self.ua[0]=0.15\n",
    "            self.ba[0]=0.2\n",
    "            self.wi[0]=0.95\n",
    "            self.wi[1]=0.8\n",
    "            self.ui[0]=0.8\n",
    "            self.bi[0]=0.65\n",
    "            self.wf[0]=0.7\n",
    "            self.wf[1]=0.45\n",
    "            self.uf[0]=0.1\n",
    "            self.bf[0]=0.15\n",
    "            self.wo[0]=0.6\n",
    "            self.wo[1]=0.4\n",
    "            self.uo[0]=0.25\n",
    "            self.bo[0]=0.1\n",
    "        \n",
    "    def cleanLSTM(self):\n",
    "        # Forward Propogation Parameters\n",
    "        self.prev_input_activation = 0\n",
    "        self.prev_input_gate = 0\n",
    "        self.prev_forget_gate = 0\n",
    "        self.prev_output_gate = 0\n",
    "        \n",
    "        self.input_activation = 0\n",
    "        self.input_gate = 0\n",
    "        self.forget_gate = 0\n",
    "        self.output_gate = 0\n",
    "        self.internal_state = np.zeros((1, 1))\n",
    "        self.output = np.zeros((1, 1))\n",
    "\n",
    "        self.prev_input_activations = []\n",
    "        self.prev_input_gates  = []\n",
    "        self.prev_output_gates  = []\n",
    "        self.prev_forget_gates  = []\n",
    "        self.prev_internal_states  = []\n",
    "        self.prev_outputs = []\n",
    "        \n",
    "        \n",
    "        # Backward Propogation Parameters\n",
    "        self.stacked_ip_weights = []\n",
    "        self.stacked_op_weights = []\n",
    "        \n",
    "        self.der_internal_state_future = np.zeros((1, 1))\n",
    "        self.delta_op_future = np.zeros((1, 1))\n",
    "        \n",
    "        self.input_weight_derivatives = 0\n",
    "        self.output_weight_derivatives = 0\n",
    "        self.bias_derivatives = 0\n",
    "\n",
    "    def update_lstmData(self, lr=.01):\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        dip = self.input_weight_derivatives\n",
    "        dop = self.output_weight_derivatives\n",
    "        db = self.bias_derivatives\n",
    "        \n",
    "        t = wa.T - (dip*lr)\n",
    "        wa.T[0] = t[0].T\n",
    "        t = wi.T - (dip*lr)\n",
    "        wi.T[0] = t[1].T\n",
    "        t = wf.T - (dip*lr)\n",
    "        wf.T[0] = t[2].T\n",
    "        t = wo.T - (dip*lr)\n",
    "        wo.T[0] = t[3].T\n",
    "        ua = ua.T - (dop*lr)[0]\n",
    "        ui = ui.T - (dop*lr)[1]\n",
    "        uf = uf.T - (dop*lr)[2]\n",
    "        uo = uo.T - (dop*lr)[3]\n",
    "        ba = ba.T - (db*lr)[0]\n",
    "        bi = bi.T - (db*lr)[1]\n",
    "        bf = bf.T - (db*lr)[2]\n",
    "        bo = bo.T - (db*lr)[3]\n",
    "        self.wa=wa\n",
    "        self.ua=ua\n",
    "        self.ba=ba\n",
    "        self.wi=wi\n",
    "        self.ui=ui\n",
    "        self.bi=bi\n",
    "        self.wf=wf\n",
    "        self.uf=uf\n",
    "        self.bf=bf\n",
    "        self.wo=wo\n",
    "        self.uo=uo\n",
    "        self.bo=bo\n",
    "\n",
    "    def printLSTMparms(self):\n",
    "        lstmData = self.getLSTMparms()\n",
    "        print('wa:', lstmData[0].shape)\n",
    "        print('ua:', lstmData[1].shape)\n",
    "        print('ba:', lstmData[2].shape)\n",
    "        print('wi:', lstmData[3].shape)\n",
    "        print('ui:', lstmData[4].shape)\n",
    "        print('bi:', lstmData[5].shape)\n",
    "        print('wf:', lstmData[6].shape)\n",
    "        print('uf:', lstmData[7].shape)\n",
    "        print('bf:', lstmData[8].shape)\n",
    "        print('wo:', lstmData[9].shape)\n",
    "        print('uo:', lstmData[10].shape)\n",
    "        print('bo:', lstmData[11].shape)\n",
    "\n",
    "\n",
    "        print('wa:', lstmData[0])\n",
    "        print('ua:', lstmData[1])\n",
    "        print('ba:', lstmData[2])\n",
    "        print('wi:', lstmData[3])\n",
    "        print('ui:', lstmData[4])\n",
    "        print('bi:', lstmData[5])\n",
    "        print('wf:', lstmData[6])\n",
    "        print('uf:', lstmData[7])\n",
    "        print('bf:', lstmData[8])\n",
    "        print('wo:', lstmData[9])\n",
    "        print('uo:', lstmData[10])\n",
    "        print('bo:', lstmData[11])\n",
    "\n",
    "    def lstm_data_transform(self, ip=None):\n",
    "        \"\"\" Changes data to the format for LSTM training \n",
    "    for sliding window approach \"\"\"\n",
    "        # Prepare the list for the transformed data\n",
    "        X, y = list(), list()\n",
    "        if ip is not None:\n",
    "            data = ip\n",
    "        else:\n",
    "            data = self.train_data\n",
    "        # Loop of the entire data set\n",
    "        for i in range(data.shape[0]):\n",
    "            # compute a new (sliding window) index\n",
    "            end_ix = i + self.batch_size\n",
    "\n",
    "            # if index is larger than the size of the dataset, we stop\n",
    "            if end_ix >= data.shape[0]:\n",
    "                break\n",
    "            # Get a sequence of data for x\n",
    "            seq_X = data[i:end_ix]\n",
    "            # Get only the last element of the sequency for y\n",
    "            seq_y = self.targets[i:end_ix]\n",
    "            # Append the list with sequencies\n",
    "            X.append(seq_X)\n",
    "            y.append(seq_y)\n",
    "        # Make final arrays\n",
    "        x_array = np.array(X)\n",
    "        y_array = np.array(y)\n",
    "        return x_array, y_array\n",
    "    \n",
    "    def plog(self, *msg, f=0):\n",
    "        if self.debug or f:\n",
    "            print(*msg)\n",
    "\n",
    "    def setLSTMparms(self, parms):\n",
    "        self.wa, self.ua, self.ba, self.wi, self.ui, self.bi, self.wf, self.uf, self.bf, self.wo, self.uo, self.bo = parms\n",
    "        \n",
    "    def getLSTMparms(self):\n",
    "        return self.wa, self.ua, self.ba, self.wi, self.ui, self.bi, self.wf, self.uf, self.bf, self.wo, self.uo, self.bo\n",
    "\n",
    "    def goForward(self, ipt, train=1):\n",
    "        #4 gates\n",
    "        # input_activation = tanh(wa [inner] input + ua [inner] prev_output + ba)\n",
    "        # input_gate  = sigmoid(wi [inner] input + ui [inner] prev_output + bi)\n",
    "        # forget_gate = sigmoid(wf [inner] input + uf [inner] prev_output + bf)\n",
    "        # output_gate = sigmoid(wo [inner] input + uo [inner] prev_output + bo)\n",
    "\n",
    "        # 2 states\n",
    "        # internal_state = (input_activation [Element wise] input_gate) + (forget_gate [Element wise] prev_internal_state)\n",
    "        # output = tanh(internal_state) [Element wise] output_gate\n",
    "    \n",
    "        plog = self.plog\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        \n",
    "        po = self.output\n",
    "        ps = self.internal_state\n",
    "        plog(\"wa : \", wa.T)\n",
    "        plog(\"ipt : \", ipt)\n",
    "        plog(\"ua : \", ua)\n",
    "        plog(\"po : \", po)\n",
    "        plog(\"ba : \", ba)\n",
    "\n",
    "        plog(\"ipt T shape\", ipt.T.shape)\n",
    "        plog(\"po shape\", po.shape)\n",
    "            \n",
    "           # print(\"incoming input = \",ippo.T)\n",
    "\n",
    "        input_plus_prev_output = np.row_stack((ipt.T, po))\n",
    "        ippo = input_plus_prev_output\n",
    "\n",
    "            \n",
    "        # input activation\n",
    "        self.input_activation = np.tanh((np.inner(wa.T, ipt)) + (np.inner(ua, po)) + ba)\n",
    "        ia = self.input_activation\n",
    "\n",
    "        # input gate\n",
    "        self.input_gate = sigmoid((np.inner(wi.T, ipt)) + (np.inner(ui, po)) + bi)\n",
    "\n",
    "        # forget gate\n",
    "        self.forget_gate = sigmoid((np.inner(wf.T, ipt)) + (np.inner(uf, po)) + bf)\n",
    "        \n",
    "        # output gate\n",
    "        self.output_gate = sigmoid((np.inner(wo.T, ipt)) + (np.inner(uo, po)) + bo)\n",
    "\n",
    "        # internal state\n",
    "        self.internal_state = (np.multiply(ia, self.input_gate)) + (np.multiply(self.forget_gate, ps))\n",
    "\n",
    "        # output\n",
    "        self.output = np.multiply(np.tanh(self.internal_state), self.output_gate)\n",
    "        \n",
    "        if train:\n",
    "            self.prev_input_activations.append(ia)\n",
    "            self.prev_input_gates.append(self.input_gate)\n",
    "            self.prev_forget_gates.append(self.forget_gate)\n",
    "            self.prev_output_gates.append(self.output_gate)\n",
    "            self.prev_internal_states.append(self.internal_state)\n",
    "            self.prev_outputs.append(self.output)\n",
    "\n",
    "        plog(\"input_activation = \",ia)\n",
    "        plog(\"input gate : \", self.input_gate)\n",
    "        plog(\"forget gate : \", self.forget_gate)\n",
    "        plog(\"output gate : \",self.output_gate)\n",
    "        plog(\"internal state\", self.internal_state)\n",
    "        plog(\"output = \",self.output)\n",
    "        plog(\"----------------------------------\")\n",
    "        return self.output\n",
    "        \n",
    "    def stackWeights(self):\n",
    "        stacked_ip_weights = np.copy(self.wa)\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wi))\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wf))\n",
    "        stacked_ip_weights = np.column_stack((stacked_ip_weights, self.wo))\n",
    "        self.stacked_ip_weights = stacked_ip_weights\n",
    "        \n",
    "        stacked_op_weights = np.copy(self.ua)\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.ui))\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.uf))\n",
    "        stacked_op_weights = np.column_stack((stacked_op_weights, self.uo))\n",
    "        self.stacked_op_weights = stacked_op_weights\n",
    "\n",
    "    def travelBack(self, targets, inputs):\n",
    "\n",
    "        plog = self.plog\n",
    "        # Unpack parameters\n",
    "        wa, ua, ba, wi, ui, bi, wf, uf, bf, wo, uo, bo = self.getLSTMparms()\n",
    "        tempo = np.zeros((1, 1))\n",
    "        loss=0\n",
    "        plog(\"Targets is\",targets)\n",
    "        plog(\"Inputs is\",inputs)\n",
    "\n",
    "        for t in reversed(range(len(self.prev_outputs))):\n",
    "\n",
    "            output = self.prev_outputs[t]\n",
    "            target = targets[t]\n",
    "            \n",
    "            next_forget_gate = np.zeros((1, 1)) if (t==len(self.prev_outputs)-1) else self.prev_forget_gates[t+1]\n",
    "            \n",
    "            plog(\"previous outputs = \", str(self.prev_outputs))\n",
    "            plog(\"target = \",str(target))\n",
    "            plog(\"output = \", str(output))\n",
    "            \n",
    "            # Track loss\n",
    "            loss = (np.power((target - output),2))/2\n",
    "            plog(\"loss = \", str(loss), f=0)\n",
    "\n",
    "            # derivative of loss with respect to output\n",
    "            der_loss_wrt_output = output - target\n",
    "            plog(\"der_loss_wrt_output = \", der_loss_wrt_output)\n",
    "\n",
    "            # derivative of output\n",
    "            der_output = der_loss_wrt_output + self.delta_op_future\n",
    "            plog(\"der_output = \", der_output)\n",
    "\n",
    "            # derivative of internal state\n",
    "            pog = self.prev_output_gates[t]\n",
    "            ps = self.prev_internal_states[t]\n",
    "            dfis = der_output * pog * (1 - (np.tanh(ps))**2 ) + (self.der_internal_state_future * next_forget_gate)\n",
    "            self.der_internal_state_future = dfis\n",
    "            plog(\"der internal state = \", dfis)\n",
    "            plog(\"pog : \", pog)\n",
    "            plog(\"ps : \", ps)\n",
    "\n",
    "\n",
    "            pig = self.prev_input_gates[t]\n",
    "            pia = self.prev_input_activations[t]\n",
    "            der_input_activation = dfis * pig * (1 - pia**2)\n",
    "            plog(\"der_input_activation = \", der_input_activation)\n",
    "            stacked_ders = np.copy(der_input_activation)\n",
    "\n",
    "            der_inputg = dfis * pia * pig * (1 - pig)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_inputg))\n",
    "            plog(\"der_input = \", der_inputg)\n",
    "\n",
    "            pps = tempo if t==0 else self.prev_internal_states[t-1] \n",
    "            pfg = self.prev_forget_gates[t]\n",
    "            der_forgetg = dfis * pps * pfg * (1 - pfg)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_forgetg))\n",
    "            plog(\"der_forget = \", der_forgetg)   \n",
    "            \n",
    "            plog(\"pps : \", pps, t-1)\n",
    "            plog(\"pfg : \", pfg)\n",
    "            plog(\"dfis : \", str(dfis))\n",
    "\n",
    "            der_outputg = der_output * np.tanh(ps) * pog * (1 - pog)\n",
    "            stacked_ders = np.row_stack((stacked_ders, der_outputg))\n",
    "            plog(\"der_output = \", der_outputg)\n",
    "\n",
    "            self.stackWeights()\n",
    "\n",
    "\n",
    "            der_input_state = np.dot(self.stacked_ip_weights, stacked_ders)\n",
    "            plog(\"der_input_state = \", der_input_state)\n",
    "\n",
    "            der_output_state = np.dot(self.stacked_op_weights, stacked_ders)\n",
    "            plog(\"der_output_state = \", der_output_state)\n",
    "            self.delta_op_future = der_output_state\n",
    "\n",
    "            plog(\"inputs t is : \",str(t), np.array([inputs[0][t]]))\n",
    "            der_input_weight = np.dot(stacked_ders, np.array([inputs[0][t]]))\n",
    "            self.input_weight_derivatives += der_input_weight\n",
    "            plog(\"der_input_weight : \", der_input_weight)\n",
    "\n",
    "            po = tempo if t==0 else self.prev_outputs[t-1] \n",
    "            der_op_weight = np.dot(stacked_ders, po)\n",
    "            self.output_weight_derivatives += der_op_weight\n",
    "            plog(\"der_op_weight : \", der_op_weight)\n",
    "\n",
    "            self.bias_derivatives += stacked_ders\n",
    "        return loss\n",
    "    \n",
    "    def train(self, epoch=2, lr=.01):\n",
    "        plog = self.plog\n",
    "        ip_batches, op_batches = self.lstm_data_transform()\n",
    "        #print(op_batches)\n",
    "        count = 1\n",
    "        for runit in range (epoch):\n",
    "            plog(\"Running EPOCH \", runit+1, f=0)\n",
    "\n",
    "            for ipbatch,opbatch in zip(ip_batches, op_batches):\n",
    "                self.cleanLSTM()\n",
    "                plog(\"Round \"+str(count),\" ipbatch is : \", ipbatch)\n",
    "                plog(\"Round \"+str(count),\" opbatch is : \", opbatch)\n",
    "                for ip in ipbatch:\n",
    "                    plog(\"Round \"+str(count),\" ip is \",ip)\n",
    "                    self.goForward(np.array([ip]))\n",
    "                loss = self.travelBack(opbatch, np.array([ipbatch]))\n",
    "                plog(\"Round \"+str(count),\" Forward and Backward DONE\", f=0)\n",
    "                plog(\"Round \"+str(count),\" OP DONE\")\n",
    "                plog(\"Round \"+str(count),\" OLD WEIGHTS\")\n",
    "                #self.printLSTMparms()\n",
    "                self.update_lstmData(lr)\n",
    "                plog(\"Round \"+str(count), \" NEW WEIGHTS\")\n",
    "                #self.printLSTMparms()\n",
    "                count+=1\n",
    "            if runit % 100 ==0:\n",
    "                print(\"loss at epoch\",runit,\"is \", loss)\n",
    "    \n",
    "    def goPredict(self, inputs, opscaler=None, ipscaler=None):\n",
    "        plog = self.plog\n",
    "        ip_batches, _ = self.lstm_data_transform(inputs)\n",
    "        count = 1\n",
    "\n",
    "        for ipbatch in ip_batches:\n",
    "            self.cleanLSTM()\n",
    "            plog(\"Round \"+str(count),\" ipbatch is : \", ipbatch)\n",
    "\n",
    "            for ip in ipbatch:\n",
    "                plog(\"Round \"+str(count),\" ip is \",ip)\n",
    "                output = self.goForward(np.array([ip]), train=0)\n",
    "                if ipscaler and opscaler:\n",
    "                    print(f'Current Price : {round(ipscaler.inverse_transform(np.array([ip]))[0][0],3)} \\\n",
    "                            Next Price : {round(opscaler.inverse_transform(output)[0][0], 3)} \\n')\n",
    "                else:\n",
    "                    print(f'input {ip} output {output}')\n",
    "\n",
    "            count+=1\n",
    "        \n",
    "    def goValidate(self, inputs, targets, opscaler=None, ipscaler=None, filename=\"pred.txt\"):\n",
    "        plog = self.plog\n",
    "        ip_batches, _ = self.lstm_data_transform(inputs)\n",
    "        file = open(filename,\"w\")\n",
    "        file.close()\n",
    "\n",
    "\n",
    "        for ipbatch in ip_batches:\n",
    "            self.cleanLSTM()\n",
    "            #plog(\"Round \"+str(count),\" ipbatch is : \", ipbatch)\n",
    "            count = 0\n",
    "            for ip in ipbatch:\n",
    "                target = np.array([[targets.iloc[count]['target']]])\n",
    "                #plog(\"Round \"+str(count),\" ip is \",ip)\n",
    "                output = self.goForward(np.array([ip]), train=0)\n",
    "                if ipscaler and opscaler:\n",
    "                    res = f'Current : {round(ipscaler.inverse_transform(np.array([ip]))[0][0],3)} \\tTarget : {round(opscaler.inverse_transform(target)[0][0], 3)} \\tPredicted : {round(opscaler.inverse_transform(output)[0][0], 3)}\\n'\n",
    "                    with open(filename, \"a\") as myfile:\n",
    "                        myfile.write(res)\n",
    "                    plog(res)\n",
    "                else:\n",
    "                    print(f'input {ip} output {output}')\n",
    "\n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a224017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T01:22:30.794475Z",
     "start_time": "2021-11-26T01:22:30.757825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is  [[0.05772812]]\n"
     ]
    }
   ],
   "source": [
    "ip = np.array([[1,2],[0.5,3]])\n",
    "op= np.array([ [0.5],[1.25]])\n",
    "\n",
    "ip = np.array([[1,2],[0.5,3],[1,2],[0.5,3],[1,2],[0.5,3]])\n",
    "op= np.array([ [0.2],[0.8],[0.2],[0.8],[0.2],[0.8] ])\n",
    "\n",
    "lstm = LSTM(train_data=ip, targets=op, batch_size=2, debug=0, test=0)\n",
    "lstm.train(epoch=3, lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37991b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T01:22:30.809243Z",
     "start_time": "2021-11-26T01:22:30.797805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input [1. 2.] output [[0.40790234]]\n",
      "input [0.5 3. ] output [[0.61355632]]\n",
      "input [0.5 3. ] output [[0.45351384]]\n",
      "input [1. 2.] output [[0.54682599]]\n",
      "input [1. 2.] output [[0.40790234]]\n",
      "input [0.5 3. ] output [[0.61355632]]\n",
      "input [0.5 3. ] output [[0.45351384]]\n",
      "input [1. 2.] output [[0.54682599]]\n"
     ]
    }
   ],
   "source": [
    "ip = np.array([[1,2],[0.5,3],[1,2],[0.5,3],[1,2],[0.5,3]])\n",
    "op= np.array([ [0.5],[1.25],[0.5],[1.25],[0.5],[1.25] ])\n",
    "\n",
    "lstm.goPredict(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70c7f389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T02:14:14.093192Z",
     "start_time": "2021-11-26T02:14:14.069247Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "opscaler = MinMaxScaler()\n",
    "ipscaler = MinMaxScaler()\n",
    "inputs=df.copy()\n",
    "inputs.drop(\"Date\", axis=1, inplace=True)\n",
    "\n",
    "targets = inputs.filter([\"Open\"], axis=1)\n",
    "targets.columns = ['target']\n",
    "targets[\"target\"]=targets['target'][1:].reset_index(drop=True)\n",
    "targets.iloc[-1]['target'] = targets.iloc[:-1]['target'].mean()\n",
    "inputs[['Open','High','Low','Close','Volume','Trade_count','Vwap']] = ipscaler.fit_transform(inputs[['Open','High','Low','Close','Volume','Trade_count','Vwap']])\n",
    "\n",
    "targets[['target']] = opscaler.fit_transform(targets[['target']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "89de4a52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T02:29:11.376896Z",
     "start_time": "2021-11-26T02:29:08.635811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is  [[0.01021864]]\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(train_data=inputs, targets=targets, batch_size=4, debug=0, test=0)\n",
    "lstm.train(epoch=60, lr=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1bf3ddd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T02:29:11.413396Z",
     "start_time": "2021-11-26T02:29:11.378718Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm.goValidate(inputs, targets, opscaler, ipscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8302bd10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T02:29:16.367345Z",
     "start_time": "2021-11-26T02:29:16.042181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-01 09:00:00+00:00</td>\n",
       "      <td>118.88</td>\n",
       "      <td>118.9400</td>\n",
       "      <td>118.8800</td>\n",
       "      <td>118.94</td>\n",
       "      <td>1145</td>\n",
       "      <td>5</td>\n",
       "      <td>118.902052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-01 09:25:00+00:00</td>\n",
       "      <td>118.77</td>\n",
       "      <td>118.7700</td>\n",
       "      <td>118.7700</td>\n",
       "      <td>118.77</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>118.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-01 09:30:00+00:00</td>\n",
       "      <td>118.69</td>\n",
       "      <td>118.6900</td>\n",
       "      <td>118.6900</td>\n",
       "      <td>118.69</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>118.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-01 09:40:00+00:00</td>\n",
       "      <td>118.60</td>\n",
       "      <td>118.6000</td>\n",
       "      <td>118.6000</td>\n",
       "      <td>118.60</td>\n",
       "      <td>800</td>\n",
       "      <td>3</td>\n",
       "      <td>118.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-01 09:50:00+00:00</td>\n",
       "      <td>118.64</td>\n",
       "      <td>118.6500</td>\n",
       "      <td>118.6400</td>\n",
       "      <td>118.65</td>\n",
       "      <td>3380</td>\n",
       "      <td>4</td>\n",
       "      <td>118.648817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255248</th>\n",
       "      <td>2021-11-19 23:40:00+00:00</td>\n",
       "      <td>160.88</td>\n",
       "      <td>160.8800</td>\n",
       "      <td>160.8001</td>\n",
       "      <td>160.81</td>\n",
       "      <td>3264</td>\n",
       "      <td>48</td>\n",
       "      <td>160.830570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255249</th>\n",
       "      <td>2021-11-19 23:45:00+00:00</td>\n",
       "      <td>160.80</td>\n",
       "      <td>160.8001</td>\n",
       "      <td>160.7600</td>\n",
       "      <td>160.76</td>\n",
       "      <td>6188</td>\n",
       "      <td>67</td>\n",
       "      <td>160.780349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255250</th>\n",
       "      <td>2021-11-19 23:50:00+00:00</td>\n",
       "      <td>160.73</td>\n",
       "      <td>160.7700</td>\n",
       "      <td>160.7300</td>\n",
       "      <td>160.75</td>\n",
       "      <td>4243</td>\n",
       "      <td>44</td>\n",
       "      <td>160.751499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255251</th>\n",
       "      <td>2021-11-19 23:55:00+00:00</td>\n",
       "      <td>160.72</td>\n",
       "      <td>160.8400</td>\n",
       "      <td>160.7200</td>\n",
       "      <td>160.84</td>\n",
       "      <td>8069</td>\n",
       "      <td>55</td>\n",
       "      <td>160.745768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255252</th>\n",
       "      <td>2021-11-20 00:00:00+00:00</td>\n",
       "      <td>160.80</td>\n",
       "      <td>160.8000</td>\n",
       "      <td>160.7600</td>\n",
       "      <td>160.76</td>\n",
       "      <td>2168</td>\n",
       "      <td>32</td>\n",
       "      <td>160.782647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255253 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date    Open      High       Low   Close  Volume  \\\n",
       "0       2015-12-01 09:00:00+00:00  118.88  118.9400  118.8800  118.94    1145   \n",
       "1       2015-12-01 09:25:00+00:00  118.77  118.7700  118.7700  118.77     200   \n",
       "2       2015-12-01 09:30:00+00:00  118.69  118.6900  118.6900  118.69     100   \n",
       "3       2015-12-01 09:40:00+00:00  118.60  118.6000  118.6000  118.60     800   \n",
       "4       2015-12-01 09:50:00+00:00  118.64  118.6500  118.6400  118.65    3380   \n",
       "...                           ...     ...       ...       ...     ...     ...   \n",
       "255248  2021-11-19 23:40:00+00:00  160.88  160.8800  160.8001  160.81    3264   \n",
       "255249  2021-11-19 23:45:00+00:00  160.80  160.8001  160.7600  160.76    6188   \n",
       "255250  2021-11-19 23:50:00+00:00  160.73  160.7700  160.7300  160.75    4243   \n",
       "255251  2021-11-19 23:55:00+00:00  160.72  160.8400  160.7200  160.84    8069   \n",
       "255252  2021-11-20 00:00:00+00:00  160.80  160.8000  160.7600  160.76    2168   \n",
       "\n",
       "        Trade_count        vwap  \n",
       "0                 5  118.902052  \n",
       "1                 1  118.770000  \n",
       "2                 1  118.690000  \n",
       "3                 3  118.600000  \n",
       "4                 4  118.648817  \n",
       "...             ...         ...  \n",
       "255248           48  160.830570  \n",
       "255249           67  160.780349  \n",
       "255250           44  160.751499  \n",
       "255251           55  160.745768  \n",
       "255252           32  160.782647  \n",
       "\n",
       "[255253 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ip=pd.read_csv('../dataset/apple_5min_data.csv')\n",
    "display(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f3d0e610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T02:30:15.682642Z",
     "start_time": "2021-11-26T02:30:15.354816Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "opscaler = MinMaxScaler()\n",
    "ipscaler = MinMaxScaler()\n",
    "inputs=ip.copy()\n",
    "inputs.drop(\"Date\", axis=1, inplace=True)\n",
    "\n",
    "targets = inputs.filter([\"Open\"], axis=1)\n",
    "targets.columns = ['target']\n",
    "targets[\"target\"]=targets['target'][1:].reset_index(drop=True)\n",
    "targets.iloc[-1]['target'] = targets.iloc[:-1]['target'].mean()\n",
    "\n",
    "inputs[['Open','High','Low','Close','Volume','Trade_count','vwap']] = ipscaler.fit_transform(inputs[['Open','High','Low','Close','Volume','Trade_count','vwap']])\n",
    "targets[['target']] = opscaler.fit_transform(targets[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f18aff91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T02:30:28.063739Z",
     "start_time": "2021-11-26T02:30:28.036750Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "intrain, intest, optrain, optest = train_test_split(inputs, targets, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4310d1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-26T02:30:54.656Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm = LSTM(train_data=intrain, targets=optrain, batch_size=200, debug=0, test=0)\n",
    "lstm.train(epoch=2, lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3677e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-26T02:31:25.078Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm.goValidate(iptest, optest, opscaler, ipscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c283c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
